---
title: '[오픈 소스 기반 데이터 분석] 4강 - 데이터 수집'
author: {name: mxxikr, link: 'https://github.com/mxxikr'}
date: 2025-08-30 00:00:00 +0900
category: [Data Science, Data Analysis]
tags: [knou, data-analysis]
math: true
mermaid: false
---
**<center>💡해당 게시글은 방송통신대학교 정재화 교수님의 '오픈 소스 기반 데이터 분석' 강의를 개인 공부 목적으로 메모하였습니다. </center>**

<br/><br/>

# 학습 개요

---

- 데이터 분석의 시작은 목적에 부합하는 데이터를 확보하는 것에서 출발함
- 단순히 데이터를 수집하는 것을 넘어, 분석 목적에 부합하고 분석 기법 적용이 용이한 데이터를 확보할 필요가 있음
- 이를 위해 데이터 유형과 수집 방법을 명확히 이해하고, 상황에 맞는 기술적 접근 방식을 선택할 수 있어야 함
- 데이터 수집의 개념과 필요성을 이해하고 신뢰할 수 있는 분석 결과 도출을 위해 확보해야 할 데이터 품질 요건(정확성, 완전성, 일관성 등)에 대해 학습함
- 정형, 반정형, 비정형 데이터의 구조적 특성과 각 유형에 따른 파일, API, 웹 스크래핑을 활용한 수집 전략을 비교함으로써 수집 대상 데이터에 따라 적용할 수 있는 처리 방식의 차이를 학습함

<br/><br/>

# 학습 목표

---

- 데이터 수집의 필요성과 중요성을 이해할 수 있음
- 정형/비정형/반정형 데이터의 특징을 구분할 수 있음
- API, 웹 스크래핑, 파일 등 다양한 소스에서 데이터를 수집하는 코드를 작성할 수 있음

<br/><br/>

# 강의록

---

## 데이터 수집의 이해

### 데이터 수집의 필요성

- 데이터의 수집 및 활용 능력에 따라 개인, 기업, 국가의 경쟁력이 결정

### 데이터 수집의 정의

- 단순히 데이터를 모으는 행위를 넘어 수집 된 데이터를 분석에 적합한 형태로 준비하는 과정
    - 분석 목적에 적합한 유효한 데이터를 탐색
    - 데이터를 수집할 수 있는 적절한 방법을 선택
    - 데이터의 정확성을 유지할 수 있는 형식 및 주기 등을 결정
- 비즈니스, 연구, 일상 생활, IT 서비스 등 사회 전 분야에서 의사 결정을 위해 데이터 분석 결과를 활용

### 데이터의 품질

- 데이터 수집의 어려움
    - 데이터 양의 문제
    - 데이터 다양성의 문제
    - 정확성과 일관성 문제
- 좋은 데이터의 조건
    - 신뢰할 수 있는 결과를 도출하기 위해서는 충분한 데이터의 양 뿐만 아니라 품질이 중요
    - ISO 8000는 데이터 품질을 평가하는 기준 제시
        - 정확성, 완전성, 일관성, 유효성, 적시성, 상호운영성

## 데이터의 유형

### 정형 데이터

- 미리 정의된 스키마에 따라 행과 열로 구성된 테이블 형태로 저장 되는 데이터
- 정형 데이터의 특징
    - **구조화: 미리 정의된 스키마를 따라 정의**
    - **정량적: 숫자 또는 문자로 표현되는 정량적 데이터**
    - **관계형 데이터베이스에 적합: 효율적 저장, 검색, 관리**
    - **분석 용이: 데이터 추출, 변환, 분석을 체계적 수행 가능**
- 정형 데이터의 한계
    - 예상치 못한 데이터 유형을 수용 어려움
    - 소셜 미디어와 같은 복잡한 정보 효과적 저장 어려움

### 비정형 데이터

- 미리 정의 된 구조나 스키마 없이 자유로운 형태와 다양한 내용을 담고 있는 데이터
- 비정형 데이터의 특징
    - **비구조화: 데이터 요소 간 관계 미정의**
    - **다양한 형태: 문서, 이메일, 멀티미디어 등 다양한 형태**
    - **저장 및 관리의 어려움: 특수한 저장소나 분산 파일 시스템**
    - **분석 어려움: 자연어 처리 등 고도의 분석 기술 필요**
- 전체 데이터의 약 80%를 차지하는 것으로 추정
- 정형 데이터에 비해 분석하기 어렵지만 다양한 정보와 맥락을 포함

### 반정형 데이터

- 어느 정도의 구조화된 요소를 포함하지만 정형 데이터와 같이 엄격한 스키마나 고정된 형식을 따르지 않음
- 반정형 데이터의 특징
    - **일정 수준 구조화: 태그, 키-값 쌍, 계층적 구조 등을 사용**
    - **다양한 형태: JSON, 로그 파일, 이메일 등 다양한 형태**
    - **유연성: 스키마 변경이 용이하고 확장성이 높음**
    - **분석 방법: NoSQL 데이터베이스 등으로 관리**
- 정형 데이터보다 풍부한 정보와 복잡한 관계 표현 가능
- 분석을 위해서는 구조를 파악하고 데이터를 정제하는 과정이 추가적으로 필요

## 데이터 수집 방법

### 데이터 수집 방법론

- 데이터 소스의 형태, 접근 권한, 데이터 양, 실시간성 요구 등을 고려하여 적절한 수집 방법을 선택
- 파일, 데이터베이스, API, 웹 스크래핑 등 다양한 수집 기술을 가능
- 파일 기반 데이터 수집
    - 데이터 분석의 가장 기본적으로 사용되는 방법 중 하나
    - CSV, Excel, JSON, XML 등 다양한 파일 형식 사용
    - 일회성 분석이나 배치 처리 방식의 분석에 적합
    - `pandas` 라이브러리는 파일에서 데이터를 효율적으로 읽고 처리하기 위한 기능 제공

### 파일 형식에 따른 장단점

| **분류** | **형식** | **장점** | **단점** | **주요 용도** |
| --- | --- | --- | --- | --- |
| 정형 | CSV | - 높은 범용성
- 다양한 프로그램 호환
- 간단한 구조
- SQL 호환 | - 복잡한 구조 표현 어려움
- 바이너리데이터 저장 불가
- 데이터 타입 정보 없음 | - 일회성 분석
- 배치 처리 |
|  | Excel | - 시각적 편집 가능
- 수식 및 차트 지원 | - 용량이 큰편
- 프로그래밍 처리 복잡 | - 비즈니스 리포트
- 데이터 편집 |
| 반정형 | JSON | - 계층적 구조 표현
- 웹 API 표준
- 가독성 우수 | - 바이너리데이터 저장 불가
- 중첩 구조시 복잡
- CSV 대비 용량큼 | - 웹 API,
- 설정 파일
- NoSQL |
|  | XML | - 구조화 된 데이터 표현
- 스키마 검증 | - 파싱 오버 헤드
- JSON 대비 복잡 | - 웹 서비스
- 설정 파일 |
|  | HTML | - 브라우저 호환
- 링크 구조 | - 데이터 추출 복잡
- 노이즈 많음 | - 웹스크래핑
- 웹페이지 |
| 비정형 | TXT | - 높은 호환성
- 용량 효율적
- 단순한 구조 | - 구조화 안됨
- 메타데이터 없음
- 분석 어려움 | - 로그 파일
- 자유 텍스트 |
|  | LOG | - 시간순 기록
- 디버깅 정보
- 시스템 추적 | - 정규 표현 식 필요
- 구조 불일치
- 노이즈 많음 | - 시스템 모니터링
- 에러 분석 |

### API(Application Programming Interface)

- 소프트웨어 간의 상호 작용을 가능하게 하는 인터페이스
    - 미리 정의된 규칙과 명령어 집합
    - 개방형 데이터 접근
    - 자동화된 데이터 수집 가능
- REST API 모델
    - 클라이언트는 서버에 특정 데이터를 요청하고 서버는 이에 응하여 JSON, XML과 같은 형식의 데이터를 반환
    
    ![image.png](/assets/img/knou/data-analysis/2025-08-30-knou-data-analysis-4/image.png)

### API 프로토콜의 종류

| **구분** | **HTTP/HTTPS** | **WebSocket** | **GraphQL** |
| --- | --- | --- | --- |
| **동작 방식** | 요청(request) →
응답(response) | 양방향 통신
(자유로운 데이터 교환) | 쿼리 기반 요청, 필요한
데이터만 선택적 응답 |
| **연결 방식** | 비연결 지향
(요청마다 새로운 연결) | 지속 연결 (handshake
이후 연결 유지) | 단일 엔드포인트 연결,
요청마다 명시적 질의 전송 |
| **장점** | 간단하고 호환성 높음 | 실시간 데이터 전송에
유리 (이벤트 기반) | 과도한 데이터 전송 방지,
유연한 질의 구조 제공 |
| **단점** | 실시간성 부족, 과도한
요청 발생 가능 | 구현 복잡도 높고, HTTP에 비해 지원 환경 제한됨 | 학습 필요, 캐싱 처리 어려움 |
| **활용 예시** | REST API, Open
API, 웹 페이지 통신 | 주식 시세, 채팅 앱,
실시간 알림, 게임 서버 등 | 복잡한 앱의 데이터 요청
최적화 (ex. 페이스북,
쇼핑몰) |

### 웹 스크래핑의 이해

- 프로그램을 통해 웹 사이트에서 데이터를 자동으로 추출하고 수집하는 기술
- 자동화 된 방식으로 웹 페이지를 방문하고 링크를 따라 이동하면서 웹의 구조를 탐색하는 웹 크롤링과 구별
- 웹 스크래핑 시 고려사항
    - 웹 페이지 구조 분석
    - 데이터 추출 방법
    - 웹 사이트 정책 준수
    - 정적 페이지와 동적 페이지
- `requests`, `BeautifulSoup`, `Selenium`, `Ixml` 등 다양한 파이썬 라이브러리를 활용

<br/><br/>

# 연습 문제

---

1. 데이터 수집의 품질을 평가하는 기준으로 ISO 8000이 제시한 항목에 해당하지 않는 것은?
    
    a. 가독성

2. 반정형 데이터의 대표적인 예시는 무엇인가?
    
    a. JSON 파일

3. API를 통한 데이터 수집의 주요 이점은 무엇인가?
    
    a. 실시간 데이터 접근과 자동화 된 수집이 가능함

<br/><br/>

# 정리 하기

---

- 데이터 수집은 분석 목적에 적합한 데이터를 식별하고 데이터의 품질을 확보하는 전략적 과정임
- 좋은 데이터의 조건에는 정확성, 완전성, 일관성, 유효성, 적시성, 상호 운용성이 있음
- 정형 데이터는 행과 열의 테이블 형태로 구조화 된 데이터임
- 비정형 데이터는 구조가 없는 자유로운 형태의 데이터임
- 반정형 데이터는 정형과 비정형의 중간 특성을 가진 데이터임
- 각 데이터 유형은 서로 다른 수집 및 처리 방법이 필요함
- 파일 기반 수집은 로컬 환경이나 네트워크에서 파일을 직접 읽어 처리함
- API를 통한 수집은 웹 서비스나 플랫폼에서 제공하는 인터페이스를 활용함
- 웹 스크래핑은 웹사이트에서 필요한 정보를 자동으로 추출하는 기술임