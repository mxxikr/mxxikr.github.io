---
title: "Apache Kafkaì™€ Spring Bootë¡œ êµ¬ì¶•í•˜ëŠ” ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ"
author:
  name: mxxikr
  link: https://github.com/mxxikr
date: 2025-10-12 09:00:00 +0900
category:
  - [Messaging, Kafka]
tags:
  - [kafka, apache, monitoring, spring boot]
math: false
mermaid: true
---

## ì‹œìŠ¤í…œ ê°œìš”
- ë‹¨ì¼ ì„œë²„ í™˜ê²½ì—ì„œ Docker Composeë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ê°€ìš©ì„± Kafka í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹¤ë£¸

### ì‹œë‚˜ë¦¬ì˜¤
- ì‹œìŠ¤í…œ ëª©ì 
  - ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ í™˜ê²½ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
  - ì œì¡° ê³µì •ì˜ ì˜¨ìŠµë„ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘/ë¶„ì„í•˜ì—¬ í’ˆì§ˆ ê´€ë¦¬
  - ì´ìƒ ìƒíƒœ ì¦‰ì‹œ ê°ì§€ ë° ì•Œë¦¼ìœ¼ë¡œ ë¶ˆëŸ‰ë¥  ìµœì†Œí™”

- ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ
  1. ë°ì´í„° ìˆ˜ì§‘ì¸µ
     - ê³µì •ë³„ ì˜¨ìŠµë„ ì„¼ì„œ ë„¤íŠ¸ì›Œí¬
     - ì„¼ì„œë‹¹ ì´ˆë‹¹ 1íšŒ ë°ì´í„° ìˆ˜ì§‘
     - ì´ 1000ê°œ ì„¼ì„œ (10ê°œ ê³µì • * 100ê°œ ì¸¡ì • í¬ì¸íŠ¸)
  
  2. ë°ì´í„° ì²˜ë¦¬ì¸µ
     - Kafka ê¸°ë°˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
     - Active-Active ì´ì¤‘í™” êµ¬ì„±
     - ë‹¤ì¤‘ ì»¨ìŠˆë¨¸ ê·¸ë£¹ìœ¼ë¡œ ìš©ë„ë³„ ì²˜ë¦¬
  
  3. ë°ì´í„° í™œìš©ì¸µ
     - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
     - ì´ìƒ ì§•í›„ ìë™ ê°ì§€ ë° ì•Œë¦¼
     - í’ˆì§ˆ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì ì¬

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ë° ì„¤ê³„ ì›ì¹™

- ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
  - ì²˜ë¦¬ ì„±ëŠ¥
    - ì´ˆë‹¹ 1000ê°œ ì´ìƒ ë©”ì‹œì§€ ì²˜ë¦¬
    - 10ms ì´ë‚´ ì²˜ë¦¬ ì§€ì—°
    - ë°ì´í„° ì†ì‹¤ë¥  0% (min.insync.replicas=2ë¡œ ë³´ì¥)

  - ê°€ìš©ì„±
    - 99.9% ì´ìƒ ì„œë¹„ìŠ¤ ê°€ìš©ì„±
    - Active-Active ì´ì¤‘í™”ë¡œ ë‹¨ì¼ ì¥ì•  ëŒ€ì‘
    - ìë™ ë³µêµ¬ ë° ì¬ì¡°ì •

  - ëª¨ë‹ˆí„°ë§
    - ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (15ì´ˆ ì£¼ê¸°)
    - í…”ë ˆê·¸ë¨ ì¦‰ì‹œ ì•Œë¦¼
    - ì‹œìŠ¤í…œ ìì› ëª¨ë‹ˆí„°ë§

- ê¸°ìˆ  ìŠ¤íƒ ì„ ì •
  - ì• í”Œë¦¬ì¼€ì´ì…˜: Spring Boot 3.5.6, Java 17
  - ë©”ì‹œì§•: Apache Kafka
  - ì €ì¥ì†Œ: PostgreSQL
  - ëª¨ë‹ˆí„°ë§: Prometheus, Grafana

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

<div class="mermaid">
graph TB
    subgraph "ë°ì´í„° ìƒì‚°"
        P1[Producer 1\nì •ìƒ: 1000/s\ní”¼í¬: 2000/s] -->|160B ë°ì´í„°\n40B í—¤ë”| T1
        P2[Producer 2\nì •ìƒ: 1000/s\ní”¼í¬: 2000/s] -->|160B ë°ì´í„°\n40B í—¤ë”| T1
        P3[Producer 3\nì •ìƒ: 1000/s\ní”¼í¬: 2000/s] -->|160B ë°ì´í„°\n40B í—¤ë”| T2
        
        subgraph "Spring Boot í”„ë¡œë“€ì„œ"
            P1
            P2
            P3
        end
    end
    
    subgraph "Kafka í´ëŸ¬ìŠ¤í„°"
        subgraph "í† í”½ êµ¬ì„±"
            T1[Topic 1\níŒŒí‹°ì…˜: 6ê°œ\në³µì œíŒ©í„°: 2\nISR: 2] -->|íŒŒí‹°ì…˜ 1-2\nì‹¤ì‹œê°„ ì²˜ë¦¬\n500msg/sec| CG1
            T1 -->|íŒŒí‹°ì…˜ 3-4\nDB ì €ì¥\n500msg/sec| CG2
            T1 -->|íŒŒí‹°ì…˜ 5-6\në¶„ì„ ì²˜ë¦¬\n500msg/sec| CG3
            T2[Topic 2\níŒŒí‹°ì…˜: 6ê°œ\në³µì œíŒ©í„°: 2\nISR: 2] -->|ë°±ì—… ì²˜ë¦¬\n500msg/sec| CG4
        end
        
        subgraph "ë¸Œë¡œì»¤ êµ¬ì„±"
            B1[Broker 1\n16KB ë°°ì¹˜\nmin.insync.replicas=2]
            B2[Broker 2\n16KB ë°°ì¹˜\nmin.insync.replicas=2]
            ZK[ZooKeeper\n2181 í¬íŠ¸\në©”íƒ€ë°ì´í„° ê´€ë¦¬]
            B1 <-->|Active-Active ë³µì œ| B2
            B1 <-->|ë¦¬ë” ì„ ì¶œ\nì„¤ì • ê´€ë¦¬| ZK
            B2 <-->|ë¦¬ë” ì„ ì¶œ\nì„¤ì • ê´€ë¦¬| ZK
        end
    end
    
    subgraph "ë°ì´í„° ì†Œë¹„"
        subgraph "ì»¨ìŠˆë¨¸ ê·¸ë£¹"
            CG1[Group 1\nì‹¤ì‹œê°„ ì²˜ë¦¬\në°°ì¹˜: 100ê±´/100ms\nSLA: 10ms]
            CG2[Group 2\nDB ì €ì¥\në°°ì¹˜: 500ê±´/ì´ˆ\níŠ¸ëœì­ì…˜ ì²˜ë¦¬]
            CG3[Group 3\në¶„ì„\në°°ì¹˜: 1000ê±´/5ì´ˆ\në¹„ë™ê¸° ì²˜ë¦¬]
            CG4[Group 4\në°±ì—…\në°°ì¹˜: 1000ê±´/5ì´ˆ\në¹„ë™ê¸° ì²˜ë¦¬]
        end
        
        CG1 -->|ì‹¤ì‹œê°„ ì²˜ë¦¬| MC[ë©”ëª¨ë¦¬ ìºì‹œ\n100ms ê°±ì‹ ]
        CG2 -->|ì €ì¥| DB[(PostgreSQL\në°°ì¹˜: 500\n2ì°¨ ìºì‹œ)]
        CG3 -->|5ì´ˆ ì§‘ê³„| AN[ë¶„ì„ ì„œë²„]
        CG4 -->|ë°±ì—…| BK[ë°±ì—… ìŠ¤í† ë¦¬ì§€]
    end
    
    subgraph "ëª¨ë‹ˆí„°ë§"
        B1 & B2 -->|JMX ë©”íŠ¸ë¦­| JX[JMX Exporter\në¸Œë¡œì»¤ ìƒíƒœ]
        P1 & P2 & P3 -->|ì²˜ë¦¬ëŸ‰/ì§€ì—°| AE[Actuator Endpoint]
        CG1 & CG2 & CG3 & CG4 -->|Lag/ì²˜ë¦¬ëŸ‰| AE
        
        JX & AE -->|15ì´ˆ ìˆ˜ì§‘| PR[Prometheus]
        PR -->|ëŒ€ì‹œë³´ë“œ| GF[Grafana]
        PR -->|ì„ê³„ì¹˜ ë¶„ì„| AM[Alert Manager]
        AM -->|ì‹¤ì‹œê°„ ì•Œë¦¼| TG[Telegram Bot]
        
        subgraph "ë©”íŠ¸ë¦­ ì§€í‘œ"
            MT1[ë¸Œë¡œì»¤: íŒŒí‹°ì…˜ìˆ˜/ë¦¬ë”ìˆ˜]
            MT2[ì„±ëŠ¥: ì²˜ë¦¬ëŸ‰/ì§€ì—°]
            MT3[ìì›: CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬]
            MT4[ì»¨ìŠˆë¨¸: Lag/ì»¤ë°‹ë¥ ]
        end
    end
</div>

### ìƒì„¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

1. ì²˜ë¦¬ëŸ‰ ë° ê°€ìš©ì„± ì„¤ê³„
   - ìˆ˜ì§‘ ë°ì´í„° ë¶„ì„
     - ì •ìƒ ìƒíƒœ: ì´ˆë‹¹ 1000ê°œ ì„¼ì„œ ë°ì´í„°
     - ìˆœê°„ í”¼í¬: ì´ˆë‹¹ 2000ê°œë¡œ ì¦ê°€ ê°€ëŠ¥
     - ë©”ì‹œì§€ í¬ê¸°: 200ë°”ì´íŠ¸
       - ì˜¨ë„/ìŠµë„ ë°ì´í„°: 160ë°”ì´íŠ¸
       - ë©”ì‹œì§€ í—¤ë”: 40ë°”ì´íŠ¸

   - ë¸Œë¡œì»¤ êµ¬ì„± ê²°ì •
     - ë¸Œë¡œì»¤ 2ëŒ€ ìš´ì˜
       - í•œ ëŒ€ ì¥ì•  ì‹œì—ë„ ì„œë¹„ìŠ¤ ê³„ì†í•˜ê¸° ìœ„í•¨
       - ë¶€í•˜ ë¶„ì‚°ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
     
     - ZooKeeper ì—°ë™ í•„ìˆ˜
       - ë¸Œë¡œì»¤ ë©”íƒ€ë°ì´í„° ê´€ë¦¬
       - ë¦¬ë” ì„ ì¶œ, ì„¤ì • ê´€ë¦¬
       - ë¸Œë¡œì»¤ì™€ ë³„ë„ ì„œë²„ë¡œ ìš´ì˜

   - íŒŒí‹°ì…˜ ë° ë°ì´í„° ê´€ë¦¬ ì„¤ê³„
     - 1ë‹¨ê³„: ê¸°ë³¸ ì²˜ë¦¬ëŸ‰ ë¶„ì„
       - ë‹¨ì¼ íŒŒí‹°ì…˜ ì²˜ë¦¬ëŸ‰: 500 msg/s
       - í•„ìš” íŒŒí‹°ì…˜ ìˆ˜: 2000 Ã· 500 = 4ê°œ
       - ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­: 2000 msg/s * 200B = 400KB/s
     
     - 2ë‹¨ê³„: Topic 1 ì»¨ìŠˆë¨¸ ê·¸ë£¹ ê³ ë ¤
       - ì‹¤ì‹œê°„ ì²˜ë¦¬ìš©: 2ê°œ íŒŒí‹°ì…˜
       - DB ì €ì¥ìš©: 2ê°œ íŒŒí‹°ì…˜
       - ë¶„ì„ìš©: 2ê°œ íŒŒí‹°ì…˜
       - ì´ í•„ìš”: 6ê°œ íŒŒí‹°ì…˜
     
     - 3ë‹¨ê³„: Topic 2 (ë°±ì—…) íŒŒí‹°ì…˜ ì„¤ê³„
       - ì²˜ë¦¬ëŸ‰ ìš”êµ¬ì‚¬í•­: Topic 1ê³¼ ë™ì¼
       - íŒŒí‹°ì…˜ ìˆ˜: 6ê°œ (2000 msg/s ì²˜ë¦¬ ìœ„í•´)
       - íŒŒí‹°ì…˜ ë¶„ë°°: ë‹¨ì¼ ì»¨ìŠˆë¨¸ ê·¸ë£¹ì—ì„œ ì „ì²´ íŒŒí‹°ì…˜ ì²˜ë¦¬
       - ì²˜ë¦¬ ë°©ì‹: ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
     
     - 4ë‹¨ê³„: ë°ì´í„° ë³´ì¡´ ì •ì±…
       - Topic 1: 7ì¼ ë³´ê´€ (ì‹¤ì‹œê°„/ë¶„ì„ ë°ì´í„°)
       - Topic 2: 30ì¼ ë³´ê´€ (ë°±ì—… ë°ì´í„°)
       - ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ê²½ê³  ì„ê³„ì¹˜: 80%
     
     - 5ë‹¨ê³„: ê³ ê°€ìš©ì„± ë° ì •í•©ì„± ì „ëµ
       - ë³µì œë³¸ ìˆ˜: 2 (1 ë¦¬ë” + 1 íŒ”ë¡œì›Œ)
       - ISR ì„¤ì •: 2 (ë°ì´í„° ìœ ì‹¤ ë°©ì§€)
       - Producer acks: all (ëª¨ë“  ISR í™•ì¸)
       - ë¦¬ë” ì„ ì¶œ: preferred leader auto í™œì„±í™”
       - ì¬ì‹œë„ ì •ì±…: ìµœëŒ€ 3íšŒ, ì§€ìˆ˜ ë°±ì˜¤í”„

3. ì»¨ìŠˆë¨¸ ê·¸ë£¹ ì„¤ê³„
   - ì‹¤ì‹œê°„ ì²˜ë¦¬
     - íŒŒí‹°ì…˜: 1-2ë²ˆ
     - ë°°ì¹˜: 100ê±´/100ms
     - SLA: 10ms ì´ë‚´

   - ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
     - íŒŒí‹°ì…˜: 3-4ë²ˆ
     - ë°°ì¹˜: 500ê±´/1ì´ˆ
     - íŠ¸ëœì­ì…˜ ì²˜ë¦¬

   - ë°ì´í„° ë¶„ì„
     - íŒŒí‹°ì…˜: 5-6ë²ˆ
     - ë°°ì¹˜: 1000ê±´/5ì´ˆ
     - ë¹„ë™ê¸° ì²˜ë¦¬


## í™˜ê²½ êµ¬ì„±

### Ubuntu ì„œë²„ ì¤€ë¹„

- ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
  ```bash
  # íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì—…ë°ì´íŠ¸
  sudo apt update
  
  # ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ê·¸ë ˆì´ë“œ
  sudo apt upgrade -y
  ```

### Java ê°œë°œ í™˜ê²½ ì„¤ì •
- JDK 17 ì„¤ì¹˜
  ```bash
  # JDK 17 ì„¤ì¹˜
  sudo apt install openjdk-17-jdk
  
  # JAVA_HOME í™˜ê²½ë³€ìˆ˜ ì„¤ì •
  echo "export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64" >> ~/.bashrc
  echo "export PATH=\$PATH:\$JAVA_HOME/bin" >> ~/.bashrc
  source ~/.bashrc
  ```

- Gradle ì„¤ì¹˜
  ```bash
  # SDKMAN ì„¤ì¹˜
  curl -s "https://get.sdkman.io" | bash
  source "$HOME/.sdkman/bin/sdkman-init.sh"
  
  # Gradle 8.4 ì„¤ì¹˜
  sdk install gradle 8.4
  ```

### Docker ì„¤ì¹˜
- Docker & Docker Compose ì„¤ì¹˜
  ```bash
  # Docker GPG í‚¤ ì¶”ê°€
  sudo apt install ca-certificates curl gnupg
  sudo install -m 0755 -d /etc/apt/keyrings
  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
  
  # Docker ì €ì¥ì†Œ ì¶”ê°€
  echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
  
  # Docker ì—”ì§„ ì„¤ì¹˜
  sudo apt update
  sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
  
  # ì‚¬ìš©ìë¥¼ docker ê·¸ë£¹ì— ì¶”ê°€
  sudo usermod -aG docker $USER
  newgrp docker
  ```

## Kafka í´ëŸ¬ìŠ¤í„° êµ¬ì„± 

### í† í”½ ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
- `scripts/kafka-init.sh` íŒŒì¼ ìƒì„±  

  ```bash
  #!/bin/bash
  
  # í† í”½ ìƒì„± í•¨ìˆ˜
  create_topic() {
    kafka-topics.sh --create \
      --if-not-exists \
      --bootstrap-server kafka1:9092,kafka2:9093 \
      --topic $1 \
      --partitions $2 \
      --replication-factor $3 \
      --config cleanup.policy=delete \
      --config retention.ms=$4
  }
  
  # sensor-data í† í”½ ìƒì„± (7ì¼ ë³´ì¡´)
  create_topic "sensor-data" 6 2 604800000
  
  # sensor-data-backup í† í”½ ìƒì„± (30ì¼ ë³´ì¡´)
  create_topic "sensor-data-backup" 6 2 2592000000
  
  echo "Kafka topics initialized successfully"
  ```

### Docker Compose ì„¤ì •
- `docker-compose.yml` íŒŒì¼ ìƒì„±  

  ```yaml
  version: '3.8'
  services:
    # ZooKeeper - ì¹´í”„ì¹´ ë¸Œë¡œì»¤ ë©”íƒ€ë°ì´í„° ê´€ë¦¬
    zookeeper:
      image: confluentinc/cp-zookeeper:7.5.1
      container_name: zookeeper
      ports:
        - "2181:2181"
      environment:
        ZOOKEEPER_CLIENT_PORT: 2181 # ZooKeeper í¬íŠ¸
        ZOOKEEPER_TICK_TIME: 2000   # íƒ€ì„ì•„ì›ƒ ì„¤ì •(ms)
      volumes:
        - ./data/zookeeper/data:/var/lib/zookeeper/data
        - ./data/zookeeper/log:/var/lib/zookeeper/log
    
    # Kafka Broker 1 - ì²« ë²ˆì§¸ ë¸Œë¡œì»¤
    kafka1:
      image: confluentinc/cp-kafka:7.5.1
      container_name: kafka1
      ports:
        - "9092:9092"
        - "9991:9991"
      depends_on:
        - zookeeper
      volumes:
        - ./data/kafka1/data:/var/lib/kafka/data
      environment:
        # ê¸°ë³¸ ì„¤ì •
        KAFKA_BROKER_ID: 1
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
        
        # ë³µì œ ë° ê³ ê°€ìš©ì„± ì„¤ì •
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
        KAFKA_DEFAULT_REPLICATION_FACTOR: 2
        KAFKA_MIN_INSYNC_REPLICAS: 2
        KAFKA_AUTO_LEADER_REBALANCE_ENABLE: "true"
        KAFKA_LEADER_IMBALANCE_CHECK_INTERVAL_SECONDS: 300
        
        # ë°ì´í„° ì²˜ë¦¬ ì„¤ì •
        KAFKA_MESSAGE_MAX_BYTES: 1048576
        KAFKA_COMPRESSION_TYPE: producer
        KAFKA_NUM_PARTITIONS: 6
        
        # ë°ì´í„° ë³´ì¡´ ì •ì±… - ì „ì—­ ì„¤ì •
        KAFKA_LOG_RETENTION_HOURS: 168                     # ê¸°ë³¸ 7ì¼ ë³´ì¡´
        KAFKA_LOG_SEGMENT_BYTES: 1073741824               # ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸° 1GB
        KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000      # ì²´í¬ ì£¼ê¸° 5ë¶„
        KAFKA_LOG_CLEANUP_POLICY: delete                   # ë³´ì¡´ê¸°ê°„ ì´ˆê³¼ì‹œ ì‚­ì œ

        # íŠ¸ëœì­ì…˜ ê´€ë ¨ ì„¤ì •
        KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
        KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"          # í† í”½ ìë™ ìƒì„± ë¹„í™œì„±í™”
        KAFKA_AUTO_LEADER_REBALANCE_ENABLE: "true"       # ìë™ ë¦¬ë” ë¦¬ë°¸ëŸ°ì‹± í™œì„±í™”
        KAFKA_LEADER_IMBALANCE_CHECK_INTERVAL_SECONDS: 300 # ë¦¬ë” ë°¸ëŸ°ì‹± ì²´í¬ ì£¼ê¸°
        KAFKA_JMX_PORT: 9991                             # JMX í¬íŠ¸
        KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false 
          -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka1

      # ë¦¬ì†ŒìŠ¤ ì œí•œ
      deploy:
        resources:
          limits:
            memory: 2G
          reservations:
            memory: 1G
      
      # í—¬ìŠ¤ì²´í¬
      healthcheck:
        test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list"]
        interval: 30s
        timeout: 10s
        retries: 3
      
      # ë¡œê·¸ ì„¤ì •
      logging:
        driver: "json-file"
        options:
          max-size: "100m"
          max-file: "3"
    
    # Kafka Broker 2 - ë‘ ë²ˆì§¸ ë¸Œë¡œì»¤  
    kafka2:
      image: confluentinc/cp-kafka:7.5.1 
      container_name: kafka2
      ports:
        - "9093:9093"
        - "9992:9992"
      depends_on:
        - zookeeper
      volumes:
        - ./data/kafka2/data:/var/lib/kafka/data
      environment:
        # ê¸°ë³¸ ì„¤ì •
        KAFKA_BROKER_ID: 2
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093
        
        # ë³µì œ ë° ê³ ê°€ìš©ì„± ì„¤ì •
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
        KAFKA_DEFAULT_REPLICATION_FACTOR: 2
        KAFKA_MIN_INSYNC_REPLICAS: 2
        KAFKA_AUTO_LEADER_REBALANCE_ENABLE: "true"
        KAFKA_LEADER_IMBALANCE_CHECK_INTERVAL_SECONDS: 300
        
        # ë°ì´í„° ì²˜ë¦¬ ì„¤ì •
        KAFKA_MESSAGE_MAX_BYTES: 1048576
        KAFKA_COMPRESSION_TYPE: producer
        KAFKA_NUM_PARTITIONS: 6
        
        # ë°ì´í„° ë³´ì¡´ ì •ì±… - ì „ì—­ ì„¤ì •
        KAFKA_LOG_RETENTION_HOURS: 168                     # ê¸°ë³¸ 7ì¼ ë³´ì¡´
        KAFKA_LOG_SEGMENT_BYTES: 1073741824               # ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸° 1GB
        KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000      # ì²´í¬ ì£¼ê¸° 5ë¶„
        KAFKA_LOG_CLEANUP_POLICY: delete                   # ë³´ì¡´ê¸°ê°„ ì´ˆê³¼ì‹œ ì‚­ì œ

        # íŠ¸ëœì­ì…˜ ê´€ë ¨ ì„¤ì •
        KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
        KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"          # í† í”½ ìë™ ìƒì„± ë¹„í™œì„±í™”
        KAFKA_AUTO_LEADER_REBALANCE_ENABLE: "true"       # ìë™ ë¦¬ë” ë¦¬ë°¸ëŸ°ì‹± í™œì„±í™”
        KAFKA_LEADER_IMBALANCE_CHECK_INTERVAL_SECONDS: 300 # ë¦¬ë” ë°¸ëŸ°ì‹± ì²´í¬ ì£¼ê¸°
        KAFKA_JMX_PORT: 9992                             # JMX í¬íŠ¸
        KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false 
          -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka2
          
      # ë¦¬ì†ŒìŠ¤ ì œí•œ
      deploy:
        resources:
          limits:
            memory: 2G
          reservations:
            memory: 1G
      
      # í—¬ìŠ¤ì²´í¬
      healthcheck:
        test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9093 --list"]
        interval: 30s
        timeout: 10s
        retries: 3
      
      # ë¡œê·¸ ì„¤ì •
      logging:
        driver: "json-file"
        options:
          max-size: "100m"
          max-file: "3"

    # Prometheus - ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    prometheus:
      image: prom/prometheus:v2.48.0
      container_name: prometheus
      ports:
        - "9090:9090"
      volumes:
        - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
        - ./data/prometheus:/prometheus
      command:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--storage.tsdb.retention.time=30d'
    
    # Grafana - ëŒ€ì‹œë³´ë“œ ì‹œê°í™”
    grafana:
      image: grafana/grafana:10.2.0
      container_name: grafana
      ports:
        - "3000:3000"
      environment:
        - GF_SECURITY_ADMIN_USER=admin
        - GF_SECURITY_ADMIN_PASSWORD=admin
      volumes:
        - ./data/grafana:/var/lib/grafana
      depends_on:
        - prometheus
    
    # Alert Manager - ì•Œë¦¼ ë°œì†¡
    alertmanager:
      image: prom/alertmanager:v0.26.0
      container_name: alertmanager
      ports:
        - "9094:9093"  # í˜¸ìŠ¤íŠ¸ì˜ 9094 í¬íŠ¸ë¥¼ ì»¨í…Œì´ë„ˆì˜ 9093 í¬íŠ¸ì— ë§¤í•‘
      volumes:
        - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      command:
        - '--config.file=/etc/alertmanager/alertmanager.yml'

    # Kafka í† í”½ ì´ˆê¸°í™”
    kafka-init:
      image: confluentinc/cp-kafka:7.5.1
      depends_on:
        kafka1:
          condition: service_healthy # ì‹¤ì œë¡œ ì„œë¹„ìŠ¤ê°€ ë™ì‘í•˜ëŠ” ìƒíƒœ
        kafka2:
          condition: service_healthy
      volumes:
        - ./scripts/kafka-init.sh:/scripts/kafka-init.sh
      command: >
        bash -c "
          echo 'Waiting for Kafka to be ready...' &&
          cub kafka-ready -b kafka1:9092,kafka2:9093 2 60 &&
          echo 'Initializing Kafka topics...' &&
          /scripts/kafka-init.sh"
  ```

### ëª¨ë‹ˆí„°ë§ ì„¤ì •
- Prometheus ì„¤ì • (`prometheus/prometheus.yml`)  

  ```yaml
  global:
    scrape_interval: 15s     # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì£¼ê¸°
    evaluation_interval: 15s  # ê·œì¹™ í‰ê°€ ì£¼ê¸°
  
  rule_files:
    - 'rules/*.yml'          # ì•Œë¦¼ ê·œì¹™ íŒŒì¼
  
  alerting:
    alertmanagers:
      - static_configs:
          - targets: ['alertmanager:9093']
  
  scrape_configs:
    - job_name: 'kafka'
      static_configs:
        - targets:
          - 'kafka1:9991'    # Kafka ë¸Œë¡œì»¤ 1 JMX
          - 'kafka2:9992'    # Kafka ë¸Œë¡œì»¤ 2 JMX
          
    - job_name: 'spring-actuator'
      metrics_path: '/actuator/prometheus'
      scrape_interval: 5s
      static_configs:
        - targets:
          - 'host.docker.internal:8080' # Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜
          
    - job_name: 'node-exporter'
      static_configs:
        - targets:
          - 'node-exporter:9100'  # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
  ```

- Alert Manager ì„¤ì • (`alertmanager/alertmanager.yml`)  

  ```yaml
  global:
    resolve_timeout: 5m

  route:
    receiver: 'telegram'
    group_by: ['alertname', 'severity', 'consumer_group']
    group_wait: 10s
    group_interval: 10s
    repeat_interval: 1h
    
    routes:
      - match:
          severity: critical
        group_wait: 0s
        repeat_interval: 5m
      - match:
          severity: warning
        group_wait: 30s
        repeat_interval: 15m
  
  receivers:
    - name: 'telegram'
      telegram_configs:
        - bot_token: 'YOUR_BOT_TOKEN'
          chat_id: YOUR_CHAT_ID
          parse_mode: 'HTML'
          api_url: 'https://api.telegram.org'
          message: |-
            ğŸš¨ <b>{% raw %}{{ .GroupLabels.alertname }}{% endraw %}</b>
            ì‹¬ê°ë„: {% raw %}{{ .Labels.severity }}{% endraw %}
            ì»¨ìŠˆë¨¸ ê·¸ë£¹: {% raw %}{{ .Labels.consumer_group }}{% endraw %}
            {% raw %}{{ .Annotations.description }}{% endraw %}
  ```

### í´ëŸ¬ìŠ¤í„° ì‹¤í–‰
- ë„ì»¤ ì»´í¬ì¦ˆë¡œ ì‹œì‘  

  ```bash
  # ì»¨í…Œì´ë„ˆ ì‹¤í–‰
  docker-compose up -d
  
  # ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
  docker-compose ps
  
  # ë¡œê·¸ í™•ì¸
  docker-compose logs -f
  ```

## Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ

### Gradle ì˜ì¡´ì„±
- `build.gradle` ì„¤ì •  

  ```groovy
  plugins {
      id 'java'
      id 'org.springframework.boot' version '3.5.6'
      id 'io.spring.dependency-management' version '1.1.4'
  }

  group = 'com.example'
  version = '1.0.0'
  sourceCompatibility = '17'

  repositories {
      mavenCentral()
  }

  dependencies {
      // Spring Boot
      implementation 'org.springframework.boot:spring-boot-starter'
      implementation 'org.springframework.boot:spring-boot-starter-web'
      implementation 'org.springframework.kafka:spring-kafka'
      
      // Database & Caching
      implementation 'org.springframework.boot:spring-boot-starter-data-jpa'
      implementation 'org.postgresql:postgresql'
      implementation 'org.hibernate.orm:hibernate-jcache'
      implementation 'org.ehcache:ehcache:3.10.8'
      
      // Observability
      implementation 'org.springframework.boot:spring-boot-starter-actuator'
      implementation 'io.micrometer:micrometer-registry-prometheus'
      
      // lombok
      compileOnly 'org.projectlombok:lombok'
      annotationProcessor 'org.projectlombok:lombok'
      
      // í…ŒìŠ¤íŠ¸
      testImplementation 'org.springframework.boot:spring-boot-starter-test'
      testImplementation 'org.springframework.kafka:spring-kafka-test'
  }
  ```

  ### ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
  - `application.yml` ì„¤ì •

  ```yaml
  spring:
    # Kafka ì„¤ì •
    kafka:
      bootstrap-servers: localhost:9092,localhost:9093
      producer:
        key-serializer: org.apache.kafka.common.serialization.StringSerializer
        value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
        acks: all                    # ëª¨ë“  ISR í™•ì¸
        retries: 3                   # ì¬ì‹œë„ ì •ì±…: ìµœëŒ€ 3íšŒ
        retry-backoff-ms: 1000       # ì§€ìˆ˜ ë°±ì˜¤í”„ ì‹œì‘ê°’
        batch-size: 16384            # ë°°ì¹˜ í¬ê¸° 16KB
        buffer-memory: 33554432      # ë²„í¼ ë©”ëª¨ë¦¬
        compression-type: lz4        # ë©”ì‹œì§€ ì••ì¶•
        max-request-size: 1048576    # ìµœëŒ€ ìš”ì²­ í¬ê¸° 1MB

      # ê³µí†µ ì»¨ìŠˆë¨¸ ì„¤ì •
      consumer:
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
        enable-auto-commit: false    # ìˆ˜ë™ ì»¤ë°‹
        auto-offset-reset: earliest  # ì˜¤í”„ì…‹ ì´ˆê¸°í™”
        heartbeat-interval: 3000     # í•˜íŠ¸ë¹„íŠ¸ ê°„ê²©
        session-timeout-ms: 45000    # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ

      # ì‹¤ì‹œê°„ ì²˜ë¦¬ ì»¨ìŠˆë¨¸ ì„¤ì •
      consumer-realtime:
        group-id: realtime-processor
        max-poll-records: 100        # 100ê±´/100ms
        fetch-max-wait: 100          # 100ms
        fetch-min-bytes: 1           # ìµœì†Œ í˜ì¹˜ í¬ê¸°
        max-partition-fetch-bytes: 1048576

      # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì»¨ìŠˆë¨¸ ì„¤ì •
      consumer-database:
        group-id: database-processor
        max-poll-records: 500        # 500ê±´/1ì´ˆ
        fetch-max-wait: 1000         # 1ì´ˆ
        isolation-level: read_committed  # íŠ¸ëœì­ì…˜ ì²˜ë¦¬
        fetch-min-bytes: 1024
        max-partition-fetch-bytes: 1048576

      # ë°ì´í„° ë¶„ì„ ì»¨ìŠˆë¨¸ ì„¤ì •
      consumer-analytics:
        group-id: analytics-processor
        max-poll-records: 1000       # 1000ê±´/5ì´ˆ
        fetch-max-wait: 5000         # 5ì´ˆ
        fetch-min-bytes: 2048
        max-partition-fetch-bytes: 1048576
    
    # Database ì„¤ì •
    datasource:
      url: jdbc:postgresql://localhost:5432/kafka_stream
      username: postgres
      password: postgres
      driver-class-name: org.postgresql.Driver
      hikari:
        maximum-pool-size: 10
        minimum-idle: 5
    
    # JPA ì„¤ì •
    jpa:
      hibernate:
        ddl-auto: update
      properties:
        hibernate:
          dialect: org.hibernate.dialect.PostgreSQLDialect
          format_sql: true
          show_sql: true
          generate_statistics: true
          cache:
            use_second_level_cache: true
            region.factory_class: org.hibernate.cache.jcache.JCacheRegionFactory
            provider_configuration_file_path: ehcache.xml
          jdbc:
            batch_size: 500
            batch_versioned_data: true
            order_inserts: true
            order_updates: true
    
    # ì•¡ì¶”ì—ì´í„° ì„¤ì •
    management:
      endpoints:
        web:
          exposure:
            include: health,metrics,prometheus
      metrics:
        tags:
          application: ${spring.application.name}
  ```

### ë°ì´í„° ëª¨ë¸
- `SensorDataRepository.java` - ì„¼ì„œ ë°ì´í„° ë ˆí¬ì§€í† ë¦¬  

  ```java
  /**
   * ì„¼ì„œ ë°ì´í„° ì˜ì†ì„±ì„ ê´€ë¦¬í•˜ëŠ” ë¦¬í¬ì§€í† ë¦¬ ì¸í„°í˜ì´ìŠ¤
  * JpaRepositoryë¥¼ ìƒì†í•˜ì—¬ ê¸°ë³¸ì ì¸ CRUD ì‘ì—…ê³¼ í˜ì´ì§• ê¸°ëŠ¥ì„ ì œê³µ
  */
  @Repository 
  public interface SensorDataRepository extends JpaRepository<SensorData, Long> {
  }
  ```

- `SensorData.java` - ì„¼ì„œ ë°ì´í„° ëª¨ë¸   

  ```java
  @Data
  @Entity
  @Table(name = "sensor_data")
  @Cacheable
  @org.hibernate.annotations.Cache(usage = org.hibernate.annotations.CacheConcurrencyStrategy.READ_WRITE)
  public class SensorData {
      @Id
      @GeneratedValue(strategy = GenerationType.IDENTITY)
      private Long id;
      
      @Column(name = "sensor_id", nullable = false)
      @Index(name = "idx_sensor_id")    // ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„±
      private String sensorId;
      
    
      @Column(nullable = false)
      private Double temperature;   // ì˜¨ë„ ë°ì´í„° ì»¬ëŸ¼
      
      @Column(nullable = false)
      private Double humidity;  // ìŠµë„ ë°ì´í„° ì»¬ëŸ¼
      
      @Column(nullable = false) 
      @Index(name = "idx_timestamp")    // ì‹œê°„ ê¸°ë°˜ ì¡°íšŒë¥¼ ìœ„í•œ ì¸ë±ìŠ¤
      private LocalDateTime timestamp;  // ì¸¡ì • ì‹œê°„ ì»¬ëŸ¼
      
      // ë‚™ê´€ì  ë½ì„ ìœ„í•œ ë²„ì „ ê´€ë¦¬
      // ë™ì‹œì„± ì œì–´: ì—¬ëŸ¬ íŠ¸ëœì­ì…˜ì´ ë™ì‹œì— ê°™ì€ ë°ì´í„°ë¥¼ ìˆ˜ì •í•˜ëŠ” ê²ƒì„ ë°©ì§€
      @Version
      private Long version;
  }
  ```

### ë©”ì‹œì§€ ìƒì‚°ì
- `KafkaProducerConfig.java` - ìƒì‚°ì ì„¤ì •  

  ```java
  /**
   * Kafka í”„ë¡œë“€ì„œ ê´€ë ¨ ì„¤ì •ì„ ë‹´ë‹¹í•˜ëŠ” ì„¤ì • í´ë˜ìŠ¤
  * ë©”ì‹œì§€ ì§ë ¬í™”, ë¸Œë¡œì»¤ ì—°ê²° ë“± í”„ë¡œë“€ì„œì˜ í•µì‹¬ ì„¤ì •ì„ ì •ì˜
  */
  @Configuration  // ìŠ¤í”„ë§ ì„¤ì • í´ë˜ìŠ¤ì„ì„ í‘œì‹œ
  public class KafkaProducerConfig {
      
      /**
       * Kafka í”„ë¡œë“€ì„œ íŒ©í† ë¦¬ ë¹ˆ ìƒì„±
       * í”„ë¡œë“€ì„œì˜ ê¸°ë³¸ ì„¤ì •ì„ êµ¬ì„±í•˜ê³  ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ ì œê³µ
       *
       * @return ì„¤ì •ì´ ì™„ë£Œëœ í”„ë¡œë“€ì„œ íŒ©í† ë¦¬
       */
      @Bean
      public ProducerFactory<String, SensorData> producerFactory() {
          Map<String, Object> config = new HashMap<>();
          // ë¸Œë¡œì»¤ ì„œë²„ ë¦¬ìŠ¤íŠ¸ ì„¤ì •
          config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092,localhost:9093");
          // ë©”ì‹œì§€ í‚¤ì˜ ì§ë ¬í™” ë°©ì‹ ì„¤ì •
          config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
          // ë©”ì‹œì§€ ê°’ì˜ ì§ë ¬í™” ë°©ì‹ ì„¤ì • (JSON í˜•ì‹)
          config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
          return new DefaultKafkaProducerFactory<>(config);
      }
      
      /**
       * Kafka í…œí”Œë¦¿ ë¹ˆ ìƒì„±
       *
       * @return ì„¤ì •ëœ Kafka í…œí”Œë¦¿
       */
      @Bean
      public KafkaTemplate<String, SensorData> kafkaTemplate() {
          return new KafkaTemplate<>(producerFactory());
      }
  }
  ```

- `SensorDataProducer.java` - ì„¼ì„œ ë°ì´í„° ìƒì‚°   

  ```java
  /**
   * ì„¼ì„œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  Kafkaë¡œ ì „ì†¡í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
  * ì‹¤ì‹œê°„ìœ¼ë¡œ ì„¼ì„œ ë°ì´í„°ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê³  Kafka í† í”½ìœ¼ë¡œ ì „ì†¡
  */
  @Service 
  @Slf4j 
  @RequiredArgsConstructor
  public class SensorDataProducer {
      
      // Kafkaë¡œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê¸° ìœ„í•œ í…œí”Œë¦¿
      private final KafkaTemplate<String, SensorData> kafkaTemplate;
      // ì„¼ì„œ ë°ì´í„°ê°€ ì „ì†¡ë  Kafka í† í”½ ì´ë¦„
      private static final String TOPIC = "sensor-data";
      
      /**
       * ì„¼ì„œ ë°ì´í„° ìƒì„± ë° ì „ì†¡ ë©”ì„œë“œ
       * ë§¤ ë°€ë¦¬ì´ˆë§ˆë‹¤ ì‹¤í–‰ë˜ì–´ ì„ì˜ì˜ ì„¼ì„œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  Kafkaë¡œ ì „ì†¡
       */
      @Scheduled(fixedRate = 1)  // 1ms ê°„ê²©ìœ¼ë¡œ ì‹¤í–‰
      public void generateData() {
          SensorData data = new SensorData();
          data.setSensorId("SENSOR-" + ThreadLocalRandom.current().nextInt(1, 1001)); // 1ë¶€í„° 1000ê¹Œì§€ì˜ ì„¼ì„œ ID ì„ì˜ ìƒì„±
          data.setTemperature(20.0 + ThreadLocalRandom.current().nextDouble() * 10); // 20-30ë„ ì‚¬ì´ì˜ ì„ì˜ ì˜¨ë„ ìƒì„±
          data.setHumidity(40.0 + ThreadLocalRandom.current().nextDouble() * 20); // 40-60% ì‚¬ì´ì˜ ì„ì˜ ìŠµë„ ìƒì„±
          data.setTimestamp(LocalDateTime.now()); // í˜„ì¬ ì‹œê°„ ê¸°ë¡
          
          // CompletableFutureë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° ì „ì†¡
          kafkaTemplate.send(TOPIC, data.getSensorId(), data)
              .whenComplete((result, ex) -> {
                  if (ex == null) {
                      log.info("Sent data: {} with offset: {}", 
                          data, result.getRecordMetadata().offset());
                  } else {
                      log.error("Unable to send data: {} due to: {}", 
                          data, ex.getMessage());
                  }
          });
      }
  }
  ```

### ë©”ì‹œì§€ ì†Œë¹„ì
- `KafkaConsumerConfig.java` - ì†Œë¹„ì ì„¤ì •  

  ```java
  /**
   * Kafka ì»¨ìŠˆë¨¸ ê´€ë ¨ ì„¤ì •ì„ ë‹´ë‹¹í•˜ëŠ” ì„¤ì • í´ë˜ìŠ¤
  * ë©”ì‹œì§€ ì—­ì§ë ¬í™”, ì»¨ìŠˆë¨¸ ê·¸ë£¹, ë°°ì¹˜ ì²˜ë¦¬ ë“± ì»¨ìŠˆë¨¸ì˜ í•µì‹¬ ì„¤ì •ì„ ì •ì˜
  */
  @Configuration 
  public class KafkaConsumerConfig {
      
      /**
       * Kafka ì»¨ìŠˆë¨¸ íŒ©í† ë¦¬ ë¹ˆ ìƒì„±
       * ì»¨ìŠˆë¨¸ì˜ ê¸°ë³¸ ì„¤ì •ì„ êµ¬ì„±í•˜ê³  ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±
       *
       * @return ì„¤ì •ì´ ì™„ë£Œëœ ì»¨ìŠˆë¨¸ íŒ©í† ë¦¬
       */
      @Bean
      public ConsumerFactory<String, SensorData> consumerFactory() {
          Map<String, Object> config = new HashMap<>();
          // ë¸Œë¡œì»¤ ì„œë²„ ë¦¬ìŠ¤íŠ¸ ì„¤ì •
          config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092,localhost:9093");
          // ì»¨ìŠˆë¨¸ ê·¸ë£¹ ID ì„¤ì •
          config.put(ConsumerConfig.GROUP_ID_CONFIG, "sensor-group");
          // ë©”ì‹œì§€ í‚¤ì˜ ì—­ì§ë ¬í™” ë°©ì‹ ì„¤ì •
          config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
          // ë©”ì‹œì§€ ê°’ì˜ ì—­ì§ë ¬í™” ë°©ì‹ ì„¤ì • (JSON í˜•ì‹)
          config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
          return new DefaultKafkaConsumerFactory<>(config);
      }
      
      /**
       * Kafka ë¦¬ìŠ¤ë„ˆ ì»¨í…Œì´ë„ˆ íŒ©í† ë¦¬ ë¹ˆ ìƒì„±
       *
       * @return ì„¤ì •ëœ ë¦¬ìŠ¤ë„ˆ ì»¨í…Œì´ë„ˆ íŒ©í† ë¦¬
       */
      @Bean
      public ConcurrentKafkaListenerContainerFactory<String, SensorData> kafkaListenerContainerFactory() {
          ConcurrentKafkaListenerContainerFactory<String, SensorData> factory = 
              new ConcurrentKafkaListenerContainerFactory<>();
          factory.setConsumerFactory(consumerFactory());
          factory.setBatchListener(true);                  // ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™”
          factory.setConcurrency(3);                       // ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì»¨ìŠˆë¨¸ ìŠ¤ë ˆë“œ ìˆ˜ ì„¤ì •
          factory.getContainerProperties().setPollTimeout(3000); // í´ë§ ëŒ€ê¸° ì‹œê°„ ì„¤ì •(ms)
          return factory;
      }
  }
  ```

- `SensorDataConsumer.java` - ì„¼ì„œ ë°ì´í„° ì†Œë¹„  

  ```java
  /**
   * ì„¼ì„œ ë°ì´í„°ë¥¼ ì†Œë¹„í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
  * Kafkaì—ì„œ ë©”ì‹œì§€ë¥¼ ë°°ì¹˜ë¡œ ìˆ˜ì‹ í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê³  ì´ìƒ ì§•í›„ë¥¼ ëª¨ë‹ˆí„°ë§
  */
  @Service 
  @Slf4j
  @RequiredArgsConstructor 
  public class SensorDataConsumer {
      
      private final SensorDataRepository sensorDataRepository; // ì„¼ì„œ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ë¦¬í¬ì§€í† ë¦¬
      
      /**
       * Kafka í† í”½ìœ¼ë¡œë¶€í„° ì„¼ì„œ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ìˆ˜ì‹ í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ë©”ì„œë“œ
       * ë°ì´í„°ë² ì´ìŠ¤ì— ë°°ì¹˜ ì €ì¥í•˜ê³  ì˜¨ë„ ì´ìƒ ì§•í›„ë¥¼ ëª¨ë‹ˆí„°ë§
       *
       * @param dataList   ìˆ˜ì‹ ëœ ì„¼ì„œ ë°ì´í„° ëª©ë¡
       * @param partitions ë©”ì‹œì§€ê°€ ìˆ˜ì‹ ëœ íŒŒí‹°ì…˜ ë²ˆí˜¸ ëª©ë¡
       * @param offsets    ë©”ì‹œì§€ì˜ ì˜¤í”„ì…‹ ëª©ë¡
       * @throws RuntimeException ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ë°œìƒ
       */
      @KafkaListener(
          topics = "sensor-data",          // êµ¬ë…í•  í† í”½
          groupId = "db-saver-group",      // ì»¨ìŠˆë¨¸ ê·¸ë£¹ ID
          containerFactory = "kafkaListenerContainerFactory"  // ì»¨í…Œì´ë„ˆ íŒ©í† ë¦¬
      )
      @Transactional  // íŠ¸ëœì­ì…˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì–´ë…¸í…Œì´ì…˜
      public void consume(@Payload List<SensorData> dataList) {
          
          log.info("Received batch of {} records", dataList.size());
          
          try {
              // JPAë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ì €ì¥
              sensorDataRepository.saveAll(dataList);
              
              // ê³ ì˜¨ ê²½ê³ ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ê¸°ë¡ ë° ëª¨ë‹ˆí„°ë§
              for (SensorData data : dataList) {
                  if (data.getTemperature() > 25.0) {
                      log.warn("High temperature alert: {}", data);
                  }
              }
          } catch (Exception e) {
              log.error("Error processing batch: {}", e.getMessage());
              throw new RuntimeException("Failed to process batch", e);
          }
      }
  }
  ```

## ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### Grafana ëŒ€ì‹œë³´ë“œ
- í•µì‹¬ ë©”íŠ¸ë¦­
  - ë¸Œë¡œì»¤ ìƒíƒœ: í™œì„± íŒŒí‹°ì…˜ ìˆ˜, ë¦¬ë” ìˆ˜
  - ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰: ì´ˆë‹¹ ë©”ì‹œì§€ ìˆ˜, ë°”ì´íŠ¸ ì²˜ë¦¬ëŸ‰
  - ì„±ëŠ¥ ì§€í‘œ: ìš”ì²­ ì²˜ë¦¬ ì‹œê°„, ì‹¤íŒ¨ìœ¨
  - ì»¨ìŠˆë¨¸ ìƒíƒœ: Lag, ì˜¤í”„ì…‹ ì»¤ë°‹ ì„±ê³µë¥ 
  - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©: CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ , ë””ìŠ¤í¬ I/O

### ì•Œë¦¼ ê·œì¹™
- `rules/kafka_alerts.yml` ì„¤ì •   
  
  ```yaml
  groups:
    - name: kafka_system_alerts # ë¸Œë¡œì»¤ ë° ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§
      rules:
        - alert: KafkaBrokerDown
          expr: up{job="kafka"} == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "Kafka ë¸Œë¡œì»¤ ë‹¤ìš´"
            description: "ë¸Œë¡œì»¤ {% raw %}{{ $labels.instance }}{% endraw %}ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
            
        - alert: KafkaUnderReplicatedPartitions
          expr: kafka_server_replicamanager_underreplicated_partitions > 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "ë³µì œ íŒŒí‹°ì…˜ ë¶€ì¡±"
            description: "ë¸Œë¡œì»¤ {% raw %}{{ $labels.instance }}{% endraw %}ì— ë³µì œê°€ ë¶€ì¡±í•œ íŒŒí‹°ì…˜ì´ ìˆìŠµë‹ˆë‹¤"
            
        - alert: KafkaHighCPU
          expr: rate(process_cpu_seconds_total[5m]) > 0.8
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "ë†’ì€ CPU ì‚¬ìš©ë¥ "
            description: "ì¸ìŠ¤í„´ìŠ¤ {% raw %}{{ $labels.instance }}{% endraw %}ì˜ CPU ì‚¬ìš©ë¥ ì´ 80%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤"

    - name: kafka_consumer_alerts # ì»¨ìŠˆë¨¸ ê·¸ë£¹ë³„ ì²˜ë¦¬ ì§€ì—° ëª¨ë‹ˆí„°ë§
      rules:
        # ì‹¤ì‹œê°„ ì²˜ë¦¬ ê·¸ë£¹
        - alert: KafkaRealtimeProcessorLag
          expr: kafka_consumergroup_lag{group="realtime-processor"} > 200
          for: 1m
          labels:
            severity: critical
            consumer_group: realtime-processor
          annotations:
            summary: "ì‹¤ì‹œê°„ ì²˜ë¦¬ ì§€ì—° ë°œìƒ"
            description: |
              ì‹¤ì‹œê°„ ì²˜ë¦¬ ê·¸ë£¹ì—ì„œ ì²˜ë¦¬ ì§€ì—°ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
              - ì»¨ìŠˆë¨¸ ê·¸ë£¹: {% raw %}{{ $labels.group }}{% endraw %}
              - í† í”½: {% raw %}{{ $labels.topic }}{% endraw %}
              - í˜„ì¬ Lag: {% raw %}{{ $value | printf "%.0f" }}{% endraw %}ê±´
              
        # DB ì €ì¥ ê·¸ë£¹ (ì¼ë°˜ ì²˜ë¦¬)
        - alert: KafkaDatabaseProcessorLag
          expr: kafka_consumergroup_lag{group="database-processor"} > 1000
          for: 5m
          labels:
            severity: warning
            consumer_group: database-processor
          annotations:
            summary: "DB ì €ì¥ ì²˜ë¦¬ ì§€ì—° ë°œìƒ"
            description: |
              DB ì €ì¥ ê·¸ë£¹ì—ì„œ ì²˜ë¦¬ ì§€ì—°ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
              - ì»¨ìŠˆë¨¸ ê·¸ë£¹: {% raw %}{{ $labels.group }}{% endraw %}
              - í† í”½: {% raw %}{{ $labels.topic }}{% endraw %}
              - í˜„ì¬ Lag: {% raw %}{{ $value | printf "%.0f" }}{% endraw %}ê±´
              
        # ë¶„ì„ ì²˜ë¦¬ ê·¸ë£¹ (ë°°ì¹˜ ì²˜ë¦¬)
        - alert: KafkaAnalyticsProcessorLag
          expr: kafka_consumergroup_lag{group="analytics-processor"} > 5000
          for: 10m
          labels:
            severity: info
            consumer_group: analytics-processor
          annotations:
            summary: "ë¶„ì„ ì²˜ë¦¬ ì§€ì—° ë°œìƒ"
            description: |
              ë¶„ì„ ì²˜ë¦¬ ê·¸ë£¹ì—ì„œ ë°°ì¹˜ ì²˜ë¦¬ ì§€ì—°ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
              - ì»¨ìŠˆë¨¸ ê·¸ë£¹: {% raw %}{{ $labels.group }}{% endraw %}
              - í† í”½: {% raw %}{{ $labels.topic }}{% endraw %}
              - í˜„ì¬ Lag: {% raw %}{{ $value | printf "%.0f" }}{% endraw %}ê±´
  ```

## í…ŒìŠ¤íŠ¸ ë° ìš´ì˜

### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- `KafkaLoadTest.java` - ë¶€í•˜ í…ŒìŠ¤íŠ¸  
  ```java
  @SpringBootTest
  public class KafkaLoadTest {
      @Autowired
      private KafkaTemplate<String, SensorData> kafkaTemplate;
      
      @Test
      public void loadTest() throws InterruptedException {
          int messageCount = 100000;
          CountDownLatch latch = new CountDownLatch(messageCount);
          List<Long> latencies = new ArrayList<>();
          
          long start = System.currentTimeMillis();
          
          // ë³‘ë ¬ ë©”ì‹œì§€ ì „ì†¡
          IntStream.range(0, messageCount)
              .parallel()
              .forEach(i -> {
                  SensorData data = new SensorData();
                  data.setSensorId("TEST-" + i);
                  data.setTemperature(20.0 + Math.random() * 10);
                  data.setHumidity(40.0 + Math.random() * 20);
                  data.setTimestamp(LocalDateTime.now());
                  
                  long sendTime = System.nanoTime();
                  kafkaTemplate.send("sensor-data", data.getSensorId(), data)
                      .whenComplete((result, ex) -> {
                          if (ex == null) {
                              // ì§€ì—° ì‹œê°„ ì¸¡ì • (ë§ˆì´í¬ë¡œì´ˆ ë‹¨ìœ„)
                              long latency = (System.nanoTime() - sendTime) / 1000;
                              synchronized(latencies) {
                                  latencies.add(latency);
                              }
                              latch.countDown();
                          } else {
                              log.error("Failed to send message", ex);
                          }
                      });
              });
          
          // ìµœëŒ€ 1ë¶„ê°„ ëŒ€ê¸°
          boolean completed = latch.await(1, TimeUnit.MINUTES);
          long end = System.currentTimeMillis();
          
          // ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
          double duration = (end - start) / 1000.0;
          double throughput = messageCount / duration;
          
          // ì§€ì—° ì‹œê°„ í†µê³„
          DoubleSummaryStatistics stats = latencies.stream()
              .mapToDouble(Long::doubleValue)
              .summaryStatistics();
          
          // ê²°ê³¼ ì¶œë ¥
          log.info("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼:");
          log.info("- ì´ ë©”ì‹œì§€: {} (ì„±ê³µ: {})", messageCount, latencies.size());
          log.info("- ì²˜ë¦¬ ì‹œê°„: {:.2f}ì´ˆ", duration);
          log.info("- ì²˜ë¦¬ìœ¨: {:.0f} msg/sec", throughput);
          log.info("- í‰ê·  ì§€ì—°: {:.2f}Âµs", stats.getAverage());
          log.info("- ìµœëŒ€ ì§€ì—°: {:.2f}Âµs", stats.getMax());
          log.info("- ìµœì†Œ ì§€ì—°: {:.2f}Âµs", stats.getMin());
      }
  }
  ```

## Reference

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spring for Apache Kafka](https://docs.spring.io/spring-kafka/docs/current/reference/html/)
- [Spring Boot Actuator](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html)
- [Kafka Monitoring](https://docs.confluent.io/platform/current/kafka/monitoring.html)
- [Spring Data JPA Reference](https://docs.spring.io/spring-data/jpa/docs/current/reference/html/)